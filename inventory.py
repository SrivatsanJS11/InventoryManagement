# -*- coding: utf-8 -*-
"""Inventory.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bDpFhen1ME3FTJIlBtwZlaC9L8f4XStC
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded=files.upload()

df=pd.read_csv('FMCG_data.csv')

df.head(5)

df.shape

df.info()

df.isnull().sum()

df['workers_num'] = df['workers_num'].fillna(df['workers_num'].median())

df.drop(columns=['wh_est_year'] , inplace = True)

df.describe()

import plotly.express as px

# Plotting the distribution of warehouses across different regions and zones
fig = px.histogram(
    df,
    x='zone',
    color='WH_regional_zone',
    title='Distribution of Warehouses Across Different Regions and Zones',
    text_auto=True
)

fig.show()

"""This stacked bar chart illustrates the distribution of warehouses across different regions (West, South, North, and East) and zones (Zone 1 to Zone 6). The West region has a total of 8,911 warehouses, with Zone 6 having the highest count (2,398) and Zone 1 the lowest (490). The South region has 5,682 warehouses, where Zone 6 also leads (1,364) and Zone 1 is minimal (680). The North region contains 11,282 warehouses, with Zone 6 again dominant (4,519) and Zone 1 the least (841). The East region has the smallest total of 58 warehouses, with each zone contributing similarly. This chart highlights significant regional disparities in warehouse distribution, with the North region having the highest concentration, particularly in Zone 6"""

# Number of competitors in the market across different regions and zones
fig = px.histogram(df, x='zone', y='Competitor_in_mkt', color='WH_regional_zone', title='Number of Competitors in the Market Across Different Regions and Zones', barmode='group')
fig.show()

"""This bar chart shows the number of competitors in the market across different regions (West, South, North, and East) and zones (Zone 1 to Zone 6). In the West region, Zone 6 has the highest number of competitors at around 9,000, followed by Zone 5 with approximately 5,000. In the South, Zone 4 leads with around 7,000 competitors, while other zones show lower counts. The North region also sees a peak in Zone 6, with approximately 13,000 competitors, followed by Zone 5 with around 5,000. The East region has significantly fewer competitors, with each zone contributing minimally. This chart highlights the competitive landscape, with Zone 6 being particularly prominent in both the West and North regions."""

# Impact of number of competitors on product demand (weight of product shipped)
fig = px.scatter(df, x='Competitor_in_mkt', y='product_wg_ton', color='zone', title='Impact of Competitors on Product Demand')
fig.show()

"""This scatter plot demonstrates the impact of competitors on product demand across different regions (West, North, South, and East). The x-axis represents the number of competitors in the market, while the y-axis shows product weight in tons. Each color corresponds to a different region: West (red), North (orange), South (green), and East (purple). The plot reveals a significant clustering of data points between 0 to 8 competitors, with product weight varying from 10,000 to over 50,000 tons. Notably, the South and East regions (green and purple) exhibit the highest product weights across various competitor counts. The East region also shows some outliers with up to 12 competitors. This chart highlights the relationship between market competition and product demand across different regions."""

# Frequency of government checks in different regions
fig = px.histogram(df, x='zone', y='govt_check_l3m', title='Frequency of Government Checks in Different Regions', text_auto=True)
fig.show()

"""The graph you sent depicts the frequency of government closures in four zones: North, West, South, and East. The y-axis represents the frequency, labeled as "sum of govt check," with the highest value reaching 204,827 for the North zone.exclamation The x-axis represents the zones.

Here's a breakdown of the findings for each zone:

The North zone has the most frequent government closures, at around 204,827.
The West zone has a mid-range value of government closures, at around 126,761.
The South zone has a value close to the West zone, at around 128,944.
The East zone has the least frequent government closures, at around 9,775.
Overall, the graph suggests a significant difference in the frequency of government closures between the North zone and the other three zones. The West, South, and East zones have comparable closure rates, while the North zone experiences substantially more closures.


"""

# Correlation between government checks and reported storage issues
fig = px.scatter(df, x='govt_check_l3m', y='storage_issue_reported_l3m', color='zone', title='Correlation between Government Checks and Reported Storage Issues')
fig.show()

"""The scatter plot depicts the correlation between government checks conducted in the last three months (govt_check_l3m) and reported storage issues (storage_issue_reported_l3m) across different zones. The zones are color-coded: West (blue), North (red), South (green), and East (purple). Each dot represents a warehouse, showing the frequency of government checks on the x-axis and the number of storage issues on the y-axis. There is no apparent linear trend, suggesting that frequent government checks do not necessarily correlate with the number of reported storage issues. Notably, warehouses in the South zone (green) exhibit a higher concentration of both government checks and reported storage issues."""

fig = px.histogram(df,
                   x='Location_type',
                   title='Distribution of Location Type',
                   text_auto=True,
                   category_orders={'Location_type': ['urban', 'rural']})

fig.update_layout(
    xaxis_title='Location Type',
    yaxis_title='Count',
    showlegend=False
)

fig.show()

fig = px.scatter(df,
                  x='dist_from_hub',
                  y='num_refill_req_l3m',
                  color = 'zone',
                  title='Effect of Distance from Production Hub on Number of Refills',
                  labels={
                      'dist_from_hub': 'Distance from Hub (km)',
                      'num_refill_req_l3m': 'Number of Refills (Last 3 Months)'
                  },
                  trendline='ols',
                  trendline_scope='overall',
                  template='plotly_white')

fig.show()

"""The graph shows the effect of distance from a production hub on the number of refills needed for machines over a three-month period. The x-axis represents the distance from the hub in kilometers, ranging from 0 to 250 kilometers. The y-axis represents the number of refills needed in the last three months.

There is a general downward trend in the graph, indicating that as the distance from the production hub increases, the number of refills needed decreases. This could be because machines located further away are newer models that require fewer refills, or because they are used less frequently.

It's important to note that the graph doesn't show the specific type of machine or what the refills are for.
"""

fig1 = px.box(df, x='Location_type', y='num_refill_req_l3m', title='Number of Refills Across Different Location Types')
fig1.show()

"""The graph you sent is a box plot showing the distribution of the number of refills required by location type, likely across different pharmacies. The x-axis shows the location type, which can be urban or rural. The y-axis shows the number of refills.

The box in the center of each category represents the middle 50% of the data. The line in the middle of the box represents the median. The ends of the whiskers represent the most extreme values within 1.5 times the interquartile range (IQR) from the quartile. Data points beyond the whiskers are considered outliers and are shown as individual circles.

Based on the graph, refills seem to be more frequent in urban locations. The median number of refills in urban locations is higher than in rural locations, and the interquartile range is larger, suggesting a wider spread of values in urban locations
"""

# Relation between distance from hub and transport issues
fig4 = px.scatter(df, x='dist_from_hub', y='transport_issue_l1y', color='zone', title='Relation Between Distance from Hub and Transport Issues')
fig4.show()

"""This scatter plot illustrates the relationship between the distance from the hub (dist_from_hub) and transport issues reported yearly (transport_issue_1ly) across four regions: West (blue), North (orange), South (green), and East (purple). The x-axis represents the distance from the hub in unspecified units, while the y-axis indicates the frequency of transport issues, ranging from 0 to 5. The data points are evenly distributed across the y-axis for all distances, indicating no clear correlation between the distance from the hub and the number of transport issues. Each region's data points are spread similarly, suggesting consistent transport issue patterns regardless of the zone's distance from the hub. This chart underscores that transport issues do not increase with greater distance from the hub"""

import plotly.express as px

# Filter for zones with competitor presence and aggregate
competitor_presence = df[df['Competitor_in_mkt'].notnull()].groupby('zone').size().reset_index(name='Competitor Count')

# Create scatter plot
fig = px.scatter(competitor_presence, x='zone', y='Competitor Count', size='Competitor Count',
                 color='zone', color_discrete_sequence=px.colors.qualitative.Dark24[:len(competitor_presence)],
                 hover_name='zone', size_max=50, title='Competitor Presence by Zone')

# Update layout: Adjust figure size, rotate x-axis labels, and set tighter margins
fig.update_layout(xaxis_title='Zone', yaxis_title='Competitor Count',
                  xaxis=dict(categoryorder='total ascending', tickmode='linear', tickangle=-45),
                  width=1000, height=600, margin=dict(l=35, r=50, t=30, b=100))

# Show the plot
fig.show()

"""
This bubble chart visualizes the competitor presence by zone, with each zone represented by a distinct color: East (blue), North (pink), South (green), and West (red). The x-axis categorizes the zones, while the y-axis indicates the competitor count. The bubble size reflects the number of competitors, highlighting significant differences among zones. The North zone has the highest competitor count, followed by the West and South zones. The East zone has the smallest bubble, indicating the fewest competitors. This visualization effectively communicates the distribution of competitors across different regions, emphasizing where market competition is most intense and where it is less pronounced"""

heatmap_data = df.groupby('zone')['transport_issue_l1y'].sum().reset_index()

fig = px.bar(heatmap_data, x='zone', y='transport_issue_l1y',
             color='transport_issue_l1y',
             labels={'transport_issue_l1y': 'Transportation Issue Frequency'},
             title='Transportation Issue Heatmap',
             color_continuous_scale='Viridis')

fig.update_layout(xaxis_title='Zone', yaxis_title='Total Transportation Issues')
fig.show()

"""This bar chart illustrates transportation issues across different zones, with each bar's color intensity reflecting the frequency of these issues. The x-axis represents the zones (East, North, South, and West), while the y-axis indicates the total number of transportation issues reported. The North zone, depicted in yellow, shows the highest number of transportation issues, surpassing 8000. The South and West zones follow with a significant but lesser number of issues, colored in green. The East zone, marked in dark purple, has the fewest transportation issues, under 1000. This visualization highlights the distribution and severity of transportation issues by zone, emphasizing the North zone's prominence in facing transportation challenges"""

fig = px.histogram(df,x = 'flood_impacted' , color = 'zone', title = 'Impact of Flood on Warehouses' , text_auto='T')
fig.show()

"""This graph illustrates the count of warehouses in different zones (West, North, South, and East) and their flood impact status. The x-axis represents the flood impact status, with 0 indicating not impacted and 1 indicating impacted. The y-axis shows the count of warehouses.

West Zone (Blue): Majority not impacted (7182), few impacted (32).
North Zone (Red): Majority not impacted (9226), few impacted (1052).
South Zone (Green): Majority not impacted (5741), few impacted (397).
East Zone (Purple): Majority not impacted (397), no impacted warehouses.
"""

fig = px.histogram(df,x = 'electric_supply' , color = 'zone', title = 'Electric supply in Ware houses' , text_auto='T')
fig.show()

"""This depicts the count of warehouses with and without electric supply across different zones (West, North, South, and East). The x-axis indicates the electric supply status, with 0 representing no electric supply and 1 representing available electric supply. The y-axis shows the count of warehouses.

West Zone (Blue): Majority have electric supply (5210), few lack it (2721).
North Zone (Red): Majority have electric supply (6788), some lack it (3490).
South Zone (Green): Majority have electric supply (4152), fewer lack it (2210).
East Zone (Purple): Majority have electric supply (272), very few lack it (157).
"""

# Sort the DataFrame by 'workers_num' and select the top 20 entries
df_sorted = df.sort_values(by='workers_num', ascending=False).head(20)

# Create a bar plot with better visibility
fig = px.bar(df_sorted,
             x='workers_num',
             y='wh_breakdown_l3m',
             title='Relation between Number of Workers and Breakdown (Top 20)',
             text='wh_breakdown_l3m')  # Display the values on the bars

# Customize colors and layout
fig.update_traces(marker_color='rgba(58, 71, 80, 0.6)',  # Adjust bar color and transparency
                  marker_line_color='rgba(58, 71, 80, 1.0)',  # Outline color of bars
                  marker_line_width=1.5,  # Outline width
                  textposition='outside')  # Position text outside the bars for visibility

# Further layout customizations
fig.update_layout(
    xaxis_title="Number of Workers",
    yaxis_title="Breakdowns (Last 3 Months)",
    title_x=0.5,  # Center the title
    uniformtext_minsize=8,  # Minimum font size for text
    uniformtext_mode='hide',  # If text doesn't fit, hide it
    bargap=0.2  # Gap between bars
)

# Show the figure
fig.show()

"""This shows the correlation between the number of workers (workers_num) and the frequency of warehouse breakdowns in the last three months (wh_breakdown_l3m). The x-axis represents the number of workers, ranging from 10 to 100, while the y-axis represents the number of breakdowns, ranging from 0 to 6.

Warehouses with fewer workers (10-50) exhibit a wide range of breakdowns (0-6), indicating no clear pattern.
As the number of workers increases (50-100), the frequency of breakdowns tends to stabilize, mostly around 0-3.
The plot suggests a potential negative correlation, where warehouses with more workers may experience fewer breakdowns, but this is not conclusive from the given data.
"""

fig = px.scatter(df, x='flood_impacted', y='wh_breakdown_l3m', color='zone',
                 title='Warehouse Breakdowns vs. Flood Impacted',
                 labels={'flood_impacted': 'Flood Impacted (Yes=1, No=0)', 'wh_breakdown_l3m': 'Warehouse Breakdowns (Last 3 Months)'})
fig.show()

fig = px.histogram(df, x='WH_regional_zone', y='retail_shop_num', color='WH_regional_zone',
                   title='Histogram of Number of Retail Shops by Region',
                   labels={'WH_regional_zone': 'Regional Zone', 'retail_shop_num': 'Number of Retail Shops'})
fig.show()

fig = px.violin(df, x='zone', y='WH_capacity_size', color='zone',
                title='Violin Plot of Warehouse Capacity Sizes by Zone',
                labels={'zone': 'Zone', 'WH_capacity_size': 'Warehouse Capacity Size'})
fig.show()

fig = px.pie(df, names='electric_supply', title='Electric Supply Status in Warehouses')
fig.show()

fig = px.box(df, x='zone', y='dist_from_hub', color='zone',
             title='Box Plot of Distance from Hub by Zone',
             labels={'zone': 'Zone', 'dist_from_hub': 'Distance from Hub (km)'})
fig.show()

fig = px.scatter_3d(df, x='WH_capacity_size', y='dist_from_hub', z='workers_num',
                    color='zone', size='num_refill_req_l3m',
                    title='3D Scatter Plot of Warehouse Attributes',
                    labels={'WH_capacity_size': 'Warehouse Capacity Size', 'dist_from_hub': 'Distance from Hub (km)', 'workers_num': 'Number of Workers'})
fig.show()

fig = px.funnel(df, x='num_refill_req_l3m', y='zone',
                title='Funnel Chart of Warehouse Refills(Last 3 months)',
                labels={'num_refill_req_l3m': 'Number of Refills (Last 3 Months)', 'zone': 'Zone'})
fig.show()

size_mapping = {'Small': 1, 'Mid': 2, 'Large': 3}
df['WH_capacity_size'] = df['WH_capacity_size'].map(size_mapping)
df['WH_capacity_size'] = pd.to_numeric(df['WH_capacity_size'], errors='coerce')

# Defining assumed noodle packet weight as 100 grams
df['num_SKUs'] = df.apply(lambda row: row['product_wg_ton']*1000 / 0.1, axis=1)

df.head(10)

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
categorical_columns = df.select_dtypes(include=['object']).columns
for col in categorical_columns:
    df[col] = label_encoder.fit_transform(df[col])
correlation_matrix = df.corr()
print(correlation_matrix['num_SKUs'].sort_values(ascending=False))

from sklearn.model_selection import train_test_split
import pandas as pd
selected_features = [
    "storage_issue_reported_l3m",
    "wh_breakdown_l3m",
    "Competitor_in_mkt",
    "WH_capacity_size",
    "WH_regional_zone",
    "zone"
]
X = df[selected_features]
y = df['num_SKUs']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Selected Features:")
print(X_train.columns)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

reg_model = LinearRegression()
reg_model.fit(X_train, y_train)


y_pred_reg = reg_model.predict(X_test)
mse_reg = mean_squared_error(y_test, y_pred_reg)
rmse_reg = np.sqrt(mse_reg)
r2_reg = r2_score(y_test, y_pred_reg)
print('Regression Model MSE:', mse_reg)
print('Regression Model RMSE' ,rmse_reg)
print('R2 Score:', r2_reg)

results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_reg})
fig = px.scatter(results_df, x='Actual', y='Predicted', title='Regression -Actual vs. Predicted',
                 labels={'Actual': 'Actual', 'Predicted': 'Predicted'})

fig.show()

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.metrics import accuracy_score
model = RandomForestRegressor(n_estimators=1000, random_state=42)
model.fit(X_train, y_train)
y_pred_rf = model.predict(X_test)
mse_rf = mean_squared_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mse_rf)
print('Random Forest MSE:', mse_rf)
print('Random Forest RMSE' ,rmse_rf)
r2_rf = r2_score(y_test, y_pred_rf)
print('R2 Score:', r2_rf)

results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_rf})
fig = px.scatter(results_df, x='Actual', y='Predicted', title=' Random Forest- Actual vs. Predicted',
                 labels={'Actual': 'Actual', 'Predicted': 'Predicted'})

fig.show()

#lasso and ridge regularization with cross validation
from sklearn.linear_model import LassoCV
from sklearn.linear_model import RidgeCV
lasso_cv_regressor = LassoCV(alphas=[0.1, 0.01, 0.001])
ridge_cv_regressor = RidgeCV(alphas=[0.1, 1.0])

lasso_cv_regressor.fit(X_train, y_train)
ridge_cv_regressor.fit(X_train, y_train)

best_alpha = lasso_cv_regressor.alpha_
y_pred_lasso = lasso_cv_regressor.predict(X_test)
mse_lasso = mean_squared_error(y_test, y_pred_lasso)
rmse_lasso = np.sqrt(mse_lasso)
r2_lasso = r2_score(y_test, y_pred_lasso)
print('Best alpha:', best_alpha)
print('Lasso Regression MSE:', mse_lasso)
print('Lasso Regression RMSE' ,rmse_lasso)
print('R2 Score:', r2_lasso)

best_alphaa = ridge_cv_regressor.alpha_
y_pred_ridge = ridge_cv_regressor.predict(X_test)
mse_ridge = mean_squared_error(y_test, y_pred_ridge)
rmse_ridge = np.sqrt(mse_ridge)
r2_ridge = r2_score(y_test, y_pred_ridge)
print('Best alpha:', best_alphaa)
print('Ridge Regression MSE:', mse_ridge)
print('Ridge Regression RMSE' ,rmse_ridge)
print('R2 Score:', r2_ridge)

from sklearn.linear_model import ElasticNet

elastic_model = ElasticNet(alpha=1.0, l1_ratio=0.5)
elastic_model.fit(X_train, y_train)
y_pred_elastic = elastic_model.predict(X_test)
mse_elastic = mean_squared_error(y_test, y_pred_elastic)
rmse_elastic = np.sqrt(mse_elastic)
r2_elastic = r2_score(y_test, y_pred_elastic)
print('MSE of elastic net is ' , mse_elastic)
print('RMSE of elastic net is ' ,rmse_elastic)
print('R2 Score:', r2_elastic )

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error
import numpy as np

degree = 2
polynomial_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())

polynomial_model.fit(X_train, y_train)

y_pred_poly = polynomial_model.predict(X_test)

mse_poly = mean_squared_error(y_test, y_pred_poly)
rmse_poly = np.sqrt(mse_poly)
r2_poly = r2_score(y_test, y_pred_poly)
print('Polynomial Regression MSE:', mse_poly)
print('Polynomial Regression RMSE:', rmse_poly)
print('R2 score:' , r2_poly)

# XGBoost
import xgboost as xgb
# Initialize and train the boosting model
xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train)

# Predict and evaluate
y_pred_xgb = xgb_model.predict(X_test)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mse_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)
print('XGBoost MSE:', mse_xgb)
print('XGBoost Model RMSE' ,rmse_xgb)
print('R2 Score:', r2_xgb)

results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_xgb})
fig = px.scatter(results_df, x='Actual', y='Predicted', title=' XGBoost- Actual vs. Predicted',
                 labels={'Actual': 'Actual', 'Predicted': 'Predicted'})

fig.show()

#knn regressor
from sklearn.neighbors import KNeighborsRegressor
knn_regressor = KNeighborsRegressor(n_neighbors=3)
knn_regressor.fit(X_train, y_train)

y_pred_knn = knn_regressor.predict(X_test)

mse_knn = mean_squared_error(y_test, y_pred_knn)
rmse_knn = np.sqrt(mse_knn)
r2_knn = r2_score(y_test, y_pred_knn)
print('KNN MSE:', mse_knn)
print('KNN Model RMSE' ,rmse_knn)
print('R2 Score:', r2_knn)